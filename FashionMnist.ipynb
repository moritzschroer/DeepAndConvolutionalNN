{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1d8057-88a2-4f86-be88-7af54188bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 15:57:02.156679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/5pdx68_92mb8j5ghct3fp6f00000gn/T/ipykernel_29242/379620080.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import distutils\n",
    "if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n",
    "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a84d3c8-6176-400a-a63b-35f8cfef4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(256))\n",
    "  model.add(tf.keras.layers.Activation('elu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(10))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b051ab01-5139-4814-96f6-3e302b3b6e29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'COLAB_TPU_ADDR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m----> 3\u001b[0m resolver \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mcluster_resolver\u001b[38;5;241m.\u001b[39mTPUClusterResolver(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrpc://\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOLAB_TPU_ADDR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental_connect_to_cluster(resolver)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# This is the TPU initialization code that has to be at the beginning.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "  model = create_model()\n",
    "  model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "    epochs=17,\n",
    "    steps_per_epoch=60,\n",
    "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
    "    validation_freq=17\n",
    ")\n",
    "\n",
    "model.save_weights('./fashion_mnist.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5a52b-5677-4d84-ae28-9929557c5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
    "\n",
    "\n",
    "cpu_model = create_model()\n",
    "cpu_model.load_weights('./fashion_mnist.h5')\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_predictions(images, predictions):\n",
    "  n = images.shape[0]\n",
    "  nc = int(np.ceil(n / 4))\n",
    "  f, axes = pyplot.subplots(nc, 4)\n",
    "  for i in range(nc * 4):\n",
    "    y = i // 4\n",
    "    x = i % 4\n",
    "    axes[x, y].axis('off')\n",
    "    \n",
    "    label = LABEL_NAMES[np.argmax(predictions[i])]\n",
    "    confidence = np.max(predictions[i])\n",
    "    if i > n:\n",
    "      continue\n",
    "    axes[x, y].imshow(images[i])\n",
    "    axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n",
    "\n",
    "  pyplot.gcf().set_size_inches(8, 8)  \n",
    "  plot_predictions(np.squeeze(x_test[:16]), cpu_model.predict(x_test[:16]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latestpython3",
   "language": "python",
   "name": "latestpython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
